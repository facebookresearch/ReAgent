

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>ReAgent Serving Platform (RASP) &mdash; Horizon 1.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Usage" href="usage.html" />
    <link rel="prev" title="Installation" href="installation.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Horizon
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting Started</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#what-is-rasp">What is RASP?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#installing-reagent">Installing ReAgent</a></li>
<li class="toctree-l2"><a class="reference internal" href="#store-set-up">Store set-up</a></li>
<li class="toctree-l2"><a class="reference internal" href="#user-simulator">User simulator</a></li>
<li class="toctree-l2"><a class="reference internal" href="#makin-bacon">Makin’ bacon</a></li>
<li class="toctree-l2"><a class="reference internal" href="#straight-outta-context">Straight Outta Context</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="usage.html">Usage</a></li>
</ul>
<p class="caption"><span class="caption-text">Advanced Topics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed.html">Distributed Training</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api/ml.rl.workflow.html">Workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/ml.rl.preprocessing.html">Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/ml.rl.simulators.html">Simulators</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/ml.rl.thrift.html">Thrift</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/ml.rl.training.html">Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/modules.html">All Modules</a></li>
</ul>
<p class="caption"><span class="caption-text">Others</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/facebookresearch/ReAgent">Github</a></li>
<li class="toctree-l1"><a class="reference internal" href="license.html">License</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Horizon</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>ReAgent Serving Platform (RASP)</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/rasp_tutorial.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="reagent-serving-platform-rasp">
<span id="rasp-tutorial"></span><h1>ReAgent Serving Platform (RASP)<a class="headerlink" href="#reagent-serving-platform-rasp" title="Permalink to this headline">¶</a></h1>
<p>Welcome to the ReAgent Serving Platform! This tutorial gets readers
familiar with reasoning at scale by building an artificial e-commerce
site.</p>
<div class="section" id="what-is-rasp">
<h2>What is RASP?<a class="headerlink" href="#what-is-rasp" title="Permalink to this headline">¶</a></h2>
<p>RASP is a set of scoring and ranking functions and a systematic way to
collect data and deploy models. A set of potential actions are input to
RASP and a ranked list of scores is output. The method for scoring and
ranking actions is called a decision plan. In this tutorial, we will
create several different decision plans and simulate user traffic to see
the results.</p>
</div>
<div class="section" id="installing-reagent">
<h2>Installing ReAgent<a class="headerlink" href="#installing-reagent" title="Permalink to this headline">¶</a></h2>
<p>Before beginning this tutorial, please install ReAgent by following
these instructions:
<a class="reference external" href="https://github.com/facebookresearch/ReAgent/blob/master/docs/installation.rst">https://github.com/facebookresearch/ReAgent/blob/master/docs/installation.rst</a></p>
</div>
<div class="section" id="store-set-up">
<h2>Store set-up<a class="headerlink" href="#store-set-up" title="Permalink to this headline">¶</a></h2>
<p>For this tutorial, we will be in charge of recommendations for
Pig-E-Barbeque, a pork e-store. Pig-E-Barbeque sells two products: Ribs
and Bacon. Our product manager has told us to optimize for clicks. Since
we are just starting out, we don’t know anything about our visitors, but
we know that bacon is delicious. We give bacon a score of 1.1 and ribs a
score of 1.0. (If we were optimizing for revenue, we could set the score
to the price, or we could have a custom scoring function.)</p>
<p>We also need to provide a ranking function that takes our scores and
decides which items to recommend. In Pig-E-Barbeque, we only have one
spot for recommendations, so the first item will be shown to visitors
and the second choice is discarded. If we use a greedy ranking function,
we will always show bacon (with it’s score of 1.1) and never show ribs
(with a score of 0.9). This means we will never know the true
performance of recommending ribs and can’t improve our system in the
future. This is known as the cold-start or explore-exploit problem
(TODO: Citations).</p>
<p>To avoid that problem, we will use the SoftmaxRanker, which will show
bacon 52% of the time and ribs 48% of the time. The SoftmaxRanker
operator is based on the softmax function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">e_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">e_x</span> <span class="o">/</span> <span class="n">e_x</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">softmax</span><span class="p">([</span><span class="mf">1.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]))</span>
<span class="go">[0.52497919 0.47502081]</span>
</pre></div>
</div>
<p>Here is the decision plan generator:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">softmaxranker_decision_plan</span><span class="p">():</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">SoftmaxRanker</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Bacon&quot;</span><span class="p">:</span> <span class="mf">1.1</span><span class="p">,</span> <span class="s2">&quot;Ribs&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
    <span class="k">return</span> <span class="n">DecisionPlanBuilder</span><span class="p">()</span><span class="o">.</span><span class="n">set_root</span><span class="p">(</span><span class="n">op</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
</pre></div>
</div>
<p>And here is the generated decision plan:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s2">&quot;operators&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;SoftmaxRanker_1&quot;</span><span class="p">,</span>
            <span class="s2">&quot;op_name&quot;</span><span class="p">:</span> <span class="s2">&quot;SoftmaxRanker&quot;</span><span class="p">,</span>
            <span class="s2">&quot;input_dep_map&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="s2">&quot;constant_2&quot;</span><span class="p">,</span>
                <span class="s2">&quot;values&quot;</span><span class="p">:</span> <span class="s2">&quot;constant_3&quot;</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">],</span>
    <span class="s2">&quot;constants&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;constant_2&quot;</span><span class="p">,</span>
            <span class="s2">&quot;value&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;double_value&quot;</span><span class="p">:</span> <span class="mf">1.0</span>
            <span class="p">}</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;constant_3&quot;</span><span class="p">,</span>
            <span class="s2">&quot;value&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;map_double_value&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;Bacon&quot;</span><span class="p">:</span> <span class="mf">1.1</span><span class="p">,</span>
                    <span class="s2">&quot;Ribs&quot;</span><span class="p">:</span> <span class="mf">1.0</span>
                <span class="p">}</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">],</span>
    <span class="s2">&quot;num_actions_to_choose&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;reward_function&quot;</span><span class="p">:</span> <span class="s2">&quot;reward&quot;</span><span class="p">,</span>
    <span class="s2">&quot;reward_aggregator&quot;</span><span class="p">:</span> <span class="s2">&quot;sum&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="user-simulator">
<h2>User simulator<a class="headerlink" href="#user-simulator" title="Permalink to this headline">¶</a></h2>
<p>Because this isn’t a real store, we need a way to simulate users. Our
simulator has a few rules:</p>
<ol class="arabic simple">
<li><p>Visitors click on bacon recommendations 50% of the time</p></li>
<li><p>10% of visits are by rib lovers and the rest are regular visitors</p>
<ol class="arabic simple">
<li><p>Rib lovers click on rib recommendations 90% of the time</p></li>
<li><p>Regular visitors click on rib recommendations 10%</p></li>
</ol>
</li>
</ol>
<p>We will be using the built-in web service directly for this tutorial.
The simulator code can be found at:
serving/examples/ecommerce/customer_simulator.py</p>
<p>Here is our RP config file. This tells RP where to find decision plans
and models (coming later):</p>
<p>(RP config)</p>
</div>
<div class="section" id="makin-bacon">
<h2>Makin’ bacon<a class="headerlink" href="#makin-bacon" title="Permalink to this headline">¶</a></h2>
<p>In one terminal window, start the RP server:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  ReAgent git:(master) ✗ ./serving/build/RaspCli --logtostderr
I1014 17:23:19.736086 457250240 DiskConfigProvider.cpp:10] READING CONFIGS FROM serving/examples/ecommerce/plans
I1014 17:23:19.738142 457250240 DiskConfigProvider.cpp:42] GOT CONFIG multi_armed_bandit.json AT serving/examples/ecommerce/plans/multi_armed_bandit.json
I1014 17:23:19.738286 457250240 DiskConfigProvider.cpp:46] Registered decision config: multi_armed_bandit.json
I1014 17:23:19.738932 457250240 DiskConfigProvider.cpp:42] GOT CONFIG contextual_bandit.json AT serving/examples/ecommerce/plans/contextual_bandit.json
I1014 17:23:19.739020 457250240 DiskConfigProvider.cpp:46] Registered decision config: contextual_bandit.json
I1014 17:23:19.739610 457250240 DiskConfigProvider.cpp:42] GOT CONFIG heuristic.json AT serving/examples/ecommerce/plans/heuristic.json
I1014 17:23:19.739682 457250240 DiskConfigProvider.cpp:46] Registered decision config: heuristic.json
I1014 17:23:19.739843 131715072 Server.cpp:58] STARTING SERVER
</pre></div>
</div>
<p>Then in another, run our simulator. The simulator will spawn many
threads and call RASP 10,000 times (this will take a few minutes to
complete):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  ReAgent git:(master) ✗ python serving/examples/ecommerce/customer_simulator.py heuristic.json
0
200
100
400
300
500
600
700
800
900
Average reward: 0.363
Action Distribution: {&#39;Ribs&#39;: 471, &#39;Bacon&#39;: 529}
</pre></div>
</div>
<p>As expected, we recommend Bacon 52% of the time and Ribs 48% of the
time. We get an average reward (in this case, average # of clicks) of
0.3555.</p>
<p>This is our baseline performance, but can we do better? From the log, we
can see that more bacon recommendations were clicked on:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  ReAgent git:(master) ✗ cat /tmp/rasp_logging/log.txt | grep &#39;&quot;name&quot;:&quot;Ribs&quot;}]&#39; | grep &#39;&quot;reward&quot;:0.0&#39; | wc -l
    390 # Ribs not clicked
➜  ReAgent git:(master) ✗ cat /tmp/rasp_logging/log.txt | grep &#39;&quot;name&quot;:&quot;Ribs&quot;}]&#39; | grep &#39;&quot;reward&quot;:1.0&#39; | wc -l
     88 # Ribs clicked
➜  ReAgent git:(master) ✗ cat /tmp/rasp_logging/log.txt | grep &#39;&quot;name&quot;:&quot;Bacon&quot;}]&#39; | grep &#39;&quot;reward&quot;:1.0&#39; | wc -l
    266 # Bacon clicked
➜  ReAgent git:(master) ✗ cat /tmp/rasp_logging/log.txt | grep &#39;&quot;name&quot;:&quot;Bacon&quot;}]&#39; | grep &#39;&quot;reward&quot;:0.0&#39; | wc -l
    253 # Bacon not clicked
</pre></div>
</div>
<p>This makes sense since, from our simulator definition, most people
aren’t rib-lovers and only click on ribs 10% of the time. We can change
the decision plan to use a multi-armed bandit that will learn to show
bacon much more often. For this tutorial, we will use the UCB1 bandit
ranker. Passing this to the plan generator:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ucb_decision_plan</span><span class="p">():</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">UCB</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;UCB1&quot;</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">DecisionPlanBuilder</span><span class="p">()</span><span class="o">.</span><span class="n">set_root</span><span class="p">(</span><span class="n">op</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
</pre></div>
</div>
<p>Generates this plan:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  ReAgent git:(master) ✗ cat serving/examples/ecommerce/plans/multi_armed_bandit.json
{
    &quot;operators&quot;: [
        {
            &quot;name&quot;: &quot;UCB_1&quot;,
            &quot;op_name&quot;: &quot;Ucb&quot;,
            &quot;input_dep_map&quot;: {
                &quot;method&quot;: &quot;constant_2&quot;,
                &quot;batch_size&quot;: &quot;constant_3&quot;
            }
        }
    ],
    &quot;constants&quot;: [
        {
            &quot;name&quot;: &quot;constant_2&quot;,
            &quot;value&quot;: {
                &quot;string_value&quot;: &quot;UCB1&quot;
            }
        },
        {
            &quot;name&quot;: &quot;constant_3&quot;,
            &quot;value&quot;: {
                &quot;int_value&quot;: 16
            }
        }
    ],
    &quot;num_actions_to_choose&quot;: 1,
    &quot;reward_function&quot;: &quot;reward&quot;,
    &quot;reward_aggregator&quot;: &quot;sum&quot;
}
</pre></div>
</div>
<p>Running with this new plan gives:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  ReAgent git:(master) ✗ python serving/examples/ecommerce/customer_simulator.py multi_armed_bandit.json
0
200
100
400
300
500
600
700
800
900
Average reward: 0.447
Action Distribution: {&#39;Ribs&#39;: 184, &#39;Bacon&#39;: 816}
</pre></div>
</div>
<p>This is already better than our previous score of 0.363. While we were
running, the bandit was learning and adapting the scores. Let’s run
again:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  ReAgent git:(master) ✗ python serving/examples/ecommerce/customer_simulator.py multi_armed_bandit.json
0
200
100
400
300
500
600
700
800
900
Average reward: 0.497
Action Distribution: {&#39;Bacon&#39;: 926, &#39;Ribs&#39;: 74}
</pre></div>
</div>
<p>So the new ranker chooses bacon more often and gets more reward on
average than our first plan. If we keep running, eventually the model
will stop exploring the Ribs action and the average reward will approach
50% (which is the chance of a reward that we set in our simulator).</p>
</div>
<div class="section" id="straight-outta-context">
<h2>Straight Outta Context<a class="headerlink" href="#straight-outta-context" title="Permalink to this headline">¶</a></h2>
<p>While running the store, our data scientist has discovered a way to
figure out who is a rib-lover. Now we can pass a context feature which
is 1 when the visitor is a rib lover and 0 otherwise. In this section we
will train a contextual bandit that learns to show ribs to rib lovers
and bacon to everyone else.</p>
<p>As we specified in our config, RP has been writing a log of visits and
feedback to a file. We can input this file with a training config to
ReAgent to train a contextual bandit model. First, let’s clear our
training data and start over by sending a SIGINT (control-c) to our
instance of RaspCli:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>…
I1014 17:45:36.613893 6602752 Server.cpp:58] STARTING SERVER
^C
➜  ReAgent git:(master) ✗ rm /tmp/rasp_logging/log.txt
➜  ReAgent git:(master) ✗ ./serving/build/RaspCli --logtostderr
I1014 17:48:49.674149 144418240 DiskConfigProvider.cpp:10] READING CONFIGS FROM serving/examples/ecommerce/plans
I1014 17:48:49.678155 144418240 DiskConfigProvider.cpp:42] GOT CONFIG multi_armed_bandit.json AT serving/examples/ecommerce/plans/multi_armed_bandit.json
I1014 17:48:49.679606 144418240 DiskConfigProvider.cpp:46] Registered decision config: multi_armed_bandit.json
I1014 17:48:49.680496 144418240 DiskConfigProvider.cpp:42] GOT CONFIG contextual_bandit.json AT serving/examples/ecommerce/plans/contextual_bandit.json
I1014 17:48:49.680778 144418240 DiskConfigProvider.cpp:46] Registered decision config: contextual_bandit.json
I1014 17:48:49.682201 144418240 DiskConfigProvider.cpp:42] GOT CONFIG heuristic.json AT serving/examples/ecommerce/plans/heuristic.json
I1014 17:48:49.682344 144418240 DiskConfigProvider.cpp:46] Registered decision config: heuristic.json
I1014 17:48:49.682667 65638400 Server.cpp:58] STARTING SERVER
</pre></div>
</div>
<p>Now let’s run the heuristic model a few times to generate enough data
(this may take a few minutes). At the end there should be 10000 samples
(we can verify this with the wc command):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  ReAgent git:(master) ✗ for run in {1..10}; do python serving/examples/ecommerce/customer_simulator.py heuristic.json; done
0
200
...
900
Average reward: 0.36
Action Distribution: {&#39;Bacon&#39;: 516, &#39;Ribs&#39;: 484}
➜  ReAgent git:(master) ✗ wc -l /tmp/rasp_logging/log.txt
   10000 /tmp/rasp_logging/log.txt
</pre></div>
</div>
<p>RASP’s logging format and the ReAgent models’ input format is slightly
different. Fortunately, there’s a tool to convert from one to the other:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  ReAgent git:(master) ✗ python serving/scripts/rasp_to_model.py /tmp/rasp_logging/log.txt ecom_cb_input_data/input.json
➜  ReAgent git:(master) ✗ wc -l ecom_cb_input_data/input.json
   10000 ecom_cb_input_data/input.json
</pre></div>
</div>
<p>Since we are using the contextual bandit or RL model, we need to build a
timeline:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>rm -Rf spark-warehouse derby.log metastore_db preprocessing/spark-warehouse preprocessing/metastore_db preprocessing/derby.log ; /usr/local/spark/bin/spark-submit \
  --class com.facebook.spark.rl.Preprocessor preprocessing/target/rl-preprocessing-1.1.jar \
  &quot;`cat serving/examples/ecommerce/training/timeline.json`&quot;
...
2019-10-14 19:04:18 INFO  ShutdownHookManager:54 - Shutdown hook called
2019-10-14 19:04:18 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/jm/snmq7xfn7llc1tpnjgn7889h6l6pkw/T/spark-2b6a4171-cb60-4d5e-8052-87620a0677a2
2019-10-14 19:04:18 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/jm/snmq7xfn7llc1tpnjgn7889h6l6pkw/T/spark-927dae4a-6613-4a28-9d88-4d43a03d1cf3
➜  ReAgent git:(master) ✗
</pre></div>
</div>
<p>The spark job creates a directory full of files, so we must merge into
one file for training &amp; evaluation:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  ReAgent git:(master) ✗ mkdir -p training_data
➜  ReAgent git:(master) ✗ cat ecom_cb_training/part* &gt; training_data/train.json
➜  ReAgent git:(master) ✗ cat ecom_cb_eval/part* &gt; training_data/eval.json
</pre></div>
</div>
<p>Now we run our normalization. Any time we use a deep neural network, we
need normalization to prevent some large features from drowning others.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  ReAgent git:(master) ✗ python ml/rl/workflow/create_normalization_metadata.py -p serving/examples/ecommerce/training/cb_train.json

WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.
INFO:ml.rl.preprocessing.normalization:Got feature: 0
INFO:ml.rl.preprocessing.normalization:Feature 0 normalization: NormalizationParameters(feature_type=&#39;BINARY&#39;, boxcox_lambda=None, boxcox_shift=0.0, mean=0.0, stddev=1.0, possible_values=None, quantiles=None, min_value=0.0, max_value=1.0)
INFO:ml.rl.preprocessing.normalization:Got feature: 1
INFO:ml.rl.preprocessing.normalization:Feature 1 normalization: NormalizationParameters(feature_type=&#39;BINARY&#39;, boxcox_lambda=None, boxcox_shift=0.0, mean=0.0, stddev=1.0, possible_values=None, quantiles=None, min_value=1.0, max_value=1.0)
INFO:__main__:`state_features` normalization metadata written to training_data/state_features_norm.json
</pre></div>
</div>
<p>Now we can train our contextual bandit:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  ReAgent git:(master) ✗ rm -Rf &quot;outputs/*&quot; ; python ml/rl/workflow/dqn_workflow.py -p serving/examples/ecommerce/training/cb_train.json
INFO:ml.rl.json_serialize:TYPE:
INFO:ml.rl.json_serialize:{&#39;gamma&#39;: 0.0, &#39;target_update_rate&#39;: 1.0, &#39;maxq_learning&#39;: True, &#39;epsilon&#39;: 0.2, &#39;temperature&#39;: 0.35, &#39;softmax_policy&#39;: 0}
...
INFO:ml.rl.workflow.page_handler:CPE evaluation took 0.26366519927978516 seconds.
INFO:ml.rl.workflow.base_workflow:Training finished. Processed ~6555 examples / s.
INFO:ml.rl.preprocessing.preprocessor:CUDA availability: False
INFO:ml.rl.preprocessing.preprocessor:NOT Using GPU: GPU not requested or not available.
/Users/jjg/github/Horizon/ml/rl/preprocessing/preprocessor.py:546: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can&#39;t record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif max_value.gt(MAX_FEATURE_VALUE):
/Users/jjg/github/Horizon/ml/rl/preprocessing/preprocessor.py:552: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can&#39;t record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif min_value.lt(MIN_FEATURE_VALUE):
INFO:__main__:Saving PyTorch trainer to outputs/trainer_1571105504.pt
INFO:ml.rl.workflow.base_workflow:Saving TorchScript predictor to outputs/model_1571105504.torchscript
</pre></div>
</div>
<p>At this point, we have a model in <code class="docutils literal notranslate"><span class="pre">outputs/model_*.torchscript</span></code>. We
are going to combine this scoring model with an e-greedy ranker. The
e-greedy ranker chooses the best actions most of the time, but sometimes
chooses random actions to explore:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s2">&quot;operators&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;ActionValueScoringOp&quot;</span><span class="p">,</span>
            <span class="s2">&quot;op_name&quot;</span><span class="p">:</span> <span class="s2">&quot;ActionValueScoring&quot;</span><span class="p">,</span>
            <span class="s2">&quot;input_dep_map&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="s2">&quot;model_id&quot;</span><span class="p">,</span>
                <span class="s2">&quot;snapshot_id&quot;</span><span class="p">:</span> <span class="s2">&quot;snapshot_id&quot;</span>
            <span class="p">}</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;SoftmaxRankerOp&quot;</span><span class="p">,</span>
            <span class="s2">&quot;op_name&quot;</span><span class="p">:</span> <span class="s2">&quot;SoftmaxRanker&quot;</span><span class="p">,</span>
            <span class="s2">&quot;input_dep_map&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="s2">&quot;constant_2&quot;</span><span class="p">,</span>
                <span class="s2">&quot;values&quot;</span><span class="p">:</span> <span class="s2">&quot;ActionValueScoringOp&quot;</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">],</span>
    <span class="s2">&quot;constants&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;model_id&quot;</span><span class="p">,</span>
            <span class="s2">&quot;value&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;int_value&quot;</span><span class="p">:</span> <span class="mi">0</span>
            <span class="p">}</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;snapshot_id&quot;</span><span class="p">,</span>
            <span class="s2">&quot;value&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;int_value&quot;</span><span class="p">:</span> <span class="mi">0</span>
            <span class="p">}</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;constant_2&quot;</span><span class="p">,</span>
            <span class="s2">&quot;value&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;double_value&quot;</span><span class="p">:</span> <span class="mf">0.001</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">],</span>
    <span class="s2">&quot;num_actions_to_choose&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;reward_function&quot;</span><span class="p">:</span> <span class="s2">&quot;reward&quot;</span><span class="p">,</span>
    <span class="s2">&quot;reward_aggregator&quot;</span><span class="p">:</span> <span class="s2">&quot;sum&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The “model_id” and “snapshot_id” tell us where to find the model. Let’s
put the model there so we can find it:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  ReAgent git:(master) ✗ mkdir -p /tmp/0
➜  ReAgent git:(master) ✗ cp outputs/model_*.torchscript /tmp/0/0
</pre></div>
</div>
<p>Let’s run with our model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  ReAgent git:(master) ✗ python serving/examples/ecommerce/customer_simulator.py contextual_bandit.json
0
200
100
400
300
500
600
700
800
900
Average reward: 0.52
Action Distribution: {&#39;Bacon&#39;: 883, &#39;Ribs&#39;: 117}
</pre></div>
</div>
<p>Nice! We have a reward higher than 50%, which is the click-through-rate
for bacon. This means that we must be getting most of the rib lovers. In
case you were curious, the best possible score is (0.9*0.5 + 0.1*0.9)
== 0.54. We still have some exploration in our new plan so we won’t get
exactly 0.54 even with many iterations, but we need that exploration to
generate an even better model next time when we learn more about our
customers.</p>
<p>All of the decisions made so far have been pointwise: we don’t consider
repeat visitors. ReAgent can also optimize for long-term value in
sequential decisions using reinforcement learning, but that is out of
the scope of this starting tutorial.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="usage.html" class="btn btn-neutral float-right" title="Usage" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="installation.html" class="btn btn-neutral float-left" title="Installation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Facebook Inc.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>