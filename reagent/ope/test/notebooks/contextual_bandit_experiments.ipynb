{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from reagent.ope.estimators.contextual_bandits_estimators import (\n",
    "    Action,\n",
    "    ActionDistribution,\n",
    "    ActionRewards,\n",
    "    BanditsEstimatorInput,\n",
    "    BanditsModel,\n",
    "    DMEstimator,\n",
    "    DoublyRobustEstimator,\n",
    "    IPSEstimator,\n",
    "    LogSample,\n",
    ")\n",
    "from reagent.ope.estimators.types import ActionSpace, Policy\n",
    "from reagent.ope.trainers.linear_trainers import (\n",
    "    LogisticRegressionTrainer,\n",
    "    SGDClassifierTrainer,\n",
    "    TrainingData,\n",
    "    DecisionTreeTrainer,\n",
    "    LinearTrainer\n",
    ")\n",
    "from reagent.ope.test.multiclass_bandits import (\n",
    "    MultiClassDataRow,\n",
    "    UCIMultiClassDataset,\n",
    "    MultiClassContext,\n",
    "    MultiClassModel,\n",
    "    MultiClassPolicy,\n",
    "    evaluate_all\n",
    ")\n",
    "from reagent.ope.utils import RunningAverage\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Settings\n",
    "\n",
    "Edit the experiments list with the names of UCI datasets given in reagent/test/data to produce results for each dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "DEFAULT_ITERATIONS = 500\n",
    "TEST_ROOT_PATH = '..'\n",
    "UCI_DATASET_CONFIGS = os.path.join(TEST_ROOT_PATH, 'configs')\n",
    "MAX_METRIC_NAME_LENGTH = 20\n",
    "experiments = [\"ecoli\", \"letter_recog\", \"pendigits\", \"optdigits\", \"satimage\"]\n",
    "\n",
    "experiment_params = []\n",
    "for exp in experiments:\n",
    "    with open(os.path.join(UCI_DATASET_CONFIGS, exp + '_config.json'), \"r\") as f:\n",
    "        params = json.load(f)\n",
    "        if \"dataset\" in params:\n",
    "            if \"file\" in params[\"dataset\"]:\n",
    "                params[\"dataset\"][\"file\"] = os.path.join(TEST_ROOT_PATH, params[\"dataset\"][\"file\"])\n",
    "        experiment_params.append({\"name\": exp, \"params\": params})     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run an experiment\n",
    "\n",
    "We load the given dataset, and create trainers (which will be used for generating the policies for the logger and target). To try different trainers, modify the `log_trainer` and `tgt_trainer` variables with different `LinearTrainer`s. \n",
    "\n",
    "Note that DM's performance is highly dependent on the reward model. To try different reward models, modify the trainer passed into `DMEstimator` and `DoublyRobustEstimator` with different `LinearTrainer`s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment(s)\n",
    "def run_experiment(params): \n",
    "    random.seed(1234)\n",
    "    np.random.seed(1234)\n",
    "    torch.random.manual_seed(1234)\n",
    "\n",
    "    dataset = UCIMultiClassDataset(params[\"dataset\"])\n",
    "    log_trainer = LogisticRegressionTrainer()\n",
    "    log_epsilon = 0.1\n",
    "    tgt_trainer = SGDClassifierTrainer()\n",
    "    tgt_epsilon = 0.1\n",
    "    experiments = [\n",
    "        (\n",
    "            (\n",
    "                DMEstimator(LogisticRegressionTrainer()),\n",
    "                IPSEstimator(),\n",
    "                DoublyRobustEstimator(LogisticRegressionTrainer()),\n",
    "            ),\n",
    "            1000,\n",
    "        )\n",
    "        for _ in range(100)\n",
    "    ]\n",
    "    results = evaluate_all(\n",
    "        experiments, dataset, log_trainer, log_epsilon, tgt_trainer, tgt_epsilon, 0\n",
    "    )\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Generation\n",
    "\n",
    "For each UCI dataset, we generate a logging and target policy, create a simulated dataset using the logging policy, and evaluate the target policy using DM, IPS, and DR. The bias, rmse, and variance against the ground truth is plotted for each dataset. \n",
    "\n",
    "\n",
    "For the settings with the logging policy trained with a `LogisticRegressionTrainer`, the target policy with a `SGDClassifierTrainer`, and the reward model for DM and DR trained with a `LogisticRegressionTrainer`, a sample result gives:\n",
    "\n",
    "\n",
    "![alt text](img/bias.png \"Bias\")![alt text](img/variance.png \"Bias\")![alt text](img/rmse.png \"Bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment ecoli\n"
     ]
    }
   ],
   "source": [
    "# Generate Bar Charts, a la https://arxiv.org/pdf/1511.03722.pdf\n",
    "\n",
    "def create_and_show_chart(labels, results, title):\n",
    "    # Width of each bar\n",
    "    width = 0.25\n",
    "\n",
    "    metrics = list(results.keys())\n",
    "    \n",
    "    # Set position of bar on X axis\n",
    "    barpos = [np.arange(len(results[metrics[0]]))]\n",
    "    for m in range(len(metrics)-1):\n",
    "        barpos.append([x + width for x in barpos[-1]])\n",
    "        \n",
    "    fig, ax = plt.subplots()\n",
    "    for metric, barpositions in zip(metrics, barpos):\n",
    "        ax.bar(barpositions, results[metric], width, label=metric[:MAX_METRIC_NAME_LENGTH])\n",
    "\n",
    "    ax.set_ylabel(title)\n",
    "    plt.xticks([r + width for r in range(len(labels))], labels)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "labels = []\n",
    "\n",
    "bias_result_mapping = {}\n",
    "var_result_mapping = {}\n",
    "rmse_result_mapping = {}\n",
    "\n",
    "for params in experiment_params:\n",
    "    print(\"Running experiment \" + params[\"name\"])\n",
    "    exp_results = run_experiment(params[\"params\"])\n",
    "    labels.append(params[\"name\"])\n",
    "    \n",
    "    for estimator_name, result in exp_results.items():\n",
    "        _, _, _, tgt_gt, _, _ = result.report()\n",
    "        if not estimator_name in bias_result_mapping:\n",
    "            bias_result_mapping[estimator_name] = []\n",
    "        if not estimator_name in var_result_mapping:\n",
    "            var_result_mapping[estimator_name] = []\n",
    "        if not estimator_name in rmse_result_mapping:\n",
    "            rmse_result_mapping[estimator_name] = []\n",
    "            \n",
    "        bias_result_mapping[estimator_name].append(tgt_gt.bias.cpu().numpy())\n",
    "        var_result_mapping[estimator_name].append(tgt_gt.variance.cpu().numpy())\n",
    "        rmse_result_mapping[estimator_name].append(tgt_gt.rmse.cpu().numpy())\n",
    "\n",
    "create_and_show_chart(labels, bias_result_mapping, 'Bias')\n",
    "create_and_show_chart(labels, var_result_mapping, 'RMSE')\n",
    "create_and_show_chart(labels, rmse_result_mapping, 'Variance')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
