env:
  ChangingArms:
    num_arms: 5
model:
  DiscreteDQN:
    trainer_param:
      actions:
      - 0
      - 1
      - 2
      - 3
      - 4
      - 5
      rl:
        gamma: 1.0
        target_update_rate: 0.1
        maxq_learning: true
        temperature: 10.0
      double_q_learning: true
      minibatch_size: 256
      minibatches_per_step: 1
      optimizer:
        AdamW:
          lr: 0.01
    net_builder:
      FullyConnectedWithEmbedding:
        sizes:
        - 64
        - 64
        activations:
        - leaky_relu
        - leaky_relu
        embedding_dim: 32
    eval_parameters:
      calc_cpe_in_training: false
    state_feature_config_provider:
      raw:
        float_feature_infos:
          - name: "arm0_sample"
            feature_id: 0
          - name: "arm1_sample"
            feature_id: 1
          - name: "arm2_sample"
            feature_id: 2
          - name: "arm3_sample"
            feature_id: 3
          - name: "arm4_sample"
            feature_id: 4
        id_list_feature_configs:
          - name: "legal"
            feature_id: 100
            id_mapping_name: "legal_actions"
        id_score_list_feature_configs:
          - name: "mu_changes"
            feature_id: 1000
            id_mapping_name: "arms_list"
        id_mapping_config:
          legal_actions:
            ids:
              - 1000000
              - 1000001
              - 1000002
              - 1000003
              - 1000004
              - 1000005
          arms_list:
            ids:
              - 1500000
              - 1500001
              - 1500002
              - 1500003
              - 1500004
replay_memory_size: 100000
train_every_ts: 1
train_after_ts: 20000
num_train_episodes: 10
num_eval_episodes: 10
passing_score_bar: 200
use_gpu: false
